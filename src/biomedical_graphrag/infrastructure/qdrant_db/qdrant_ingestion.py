import asyncio

from biomedical_graphrag.infrastructure.qdrant_db.qdrant_vectorstore import AsyncQdrantVectorStore
from biomedical_graphrag.utils.json_util import load_gene_json, load_pubmed_json
from biomedical_graphrag.utils.logger_util import setup_logging

logger = setup_logging()


async def ingest_data(recreate: bool = False) -> None:
    """
    Ingest data from datasets into the Qdrant vector store (async).
    Optionally recreate the collection before ingesting.
    """
    logger.info("ğŸš€ Starting Qdrant data ingestion...")

    vector_store = AsyncQdrantVectorStore()
    try:
        if recreate:
            logger.info("ğŸ”„ Recreating collection...")
            # recreate collection to ensure clean schema/state
            try:
                await vector_store.delete_collection()
            except Exception:
                # ignore if not existing
                logger.debug("Collection didn't exist, skipping deletion")
                pass
            await vector_store.create_collection()

        # Load datasets
        logger.info("ğŸ“‚ Loading datasets...")
        pubmed_data = load_pubmed_json()
        gene_data = load_gene_json()
        logger.info(
            f"ğŸ“Š Loaded {len(pubmed_data.get('papers', []))} \
            papers and {len(gene_data.get('genes', []))} genes"
        )

        # Upsert papers with attached genes in payload
        logger.info("ğŸ“¤ Starting data upsertion...")
        await vector_store.upsert_points(pubmed_data, gene_data)
        logger.info("âœ… Embeddings ingestion complete.")
    except Exception as e:
        logger.error(f"âŒ Ingestion failed: {e}")
        raise
    finally:
        await vector_store.close()
        logger.info("ğŸ”Œ Qdrant client connection closed")


if __name__ == "__main__":
    asyncio.run(ingest_data(recreate=True))

from openai import AsyncOpenAI

from biomedical_graphrag.application.services.query_vectorstore_service.prompts.qdrant_prompts import (
    QDRANT_GENERATION_PROMPT,
)
from biomedical_graphrag.config import settings
from biomedical_graphrag.infrastructure.qdrant_db.qdrant_vectorstore import AsyncQdrantVectorStore
from biomedical_graphrag.utils.logger_util import setup_logging

logger = setup_logging()


class AsyncQdrantQuery:
    """Handles querying Qdrant vector store using LangChain for natural language questions (async)."""

    def __init__(self) -> None:
        """
        Initialize the async Qdrant client with connection parameters.
        """
        self.url = settings.qdrant.url
        self.api_key = settings.qdrant.api_key
        self.collection_name = settings.qdrant.collection_name
        self.embedding_dimension = settings.qdrant.embedding_dimension

        self.openai_client = AsyncOpenAI(api_key=settings.openai.api_key.get_secret_value())

        self.qdrant_client = AsyncQdrantVectorStore()

    async def close(self) -> None:
        """Close the async Qdrant client."""
        await self.qdrant_client.close()

    async def retrieve_documents(self, question: str, top_k: int = 5) -> list[dict]:
        """
        Query the Qdrant vector store for similar documents (async).

        Args:
            question (str): Input question to query.
            top_k (int): Number of top similar documents to retrieve.
        Returns:
            List of dictionaries containing the top_k similar documents.
        """
        embedding = await self.qdrant_client._dense_vectors(question)

        search_result = await self.qdrant_client.client.query_points(
            collection_name=self.collection_name,
            query=embedding,
            using="Dense",
            limit=top_k,
            with_payload=True,
        )
        results = [
            {
                "id": point.id,
                "score": point.score,
                "payload": point.payload,
            }
            for point in search_result.points
        ]
        return results

    async def get_answer(self, question: str) -> str:
        """
        Get an answer to the question by retrieving relevant documents from Qdrant (async).

        Args:
            question (str): The question to answer.
        Returns:
            str: The answer generated from the retrieved documents.
        """

        context = QDRANT_GENERATION_PROMPT.format(
            question=question,
            context="\n".join(
                f"Document ID: {doc['id']}, \
                  Content: {doc['payload']}"
                for doc in await self.retrieve_documents(question)
            ),
        )
        logger.debug(f"Qdrant context: {context}")

        response = await self.openai_client.chat.completions.create(
            model=settings.openai.model,
            messages=[{"role": "user", "content": context}],
            max_tokens=settings.openai.max_tokens,
        )
        return response.choices[0].message.content or ""
